{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgCfVD4d405f"
      },
      "source": [
        "# Set up environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcQm7Czt5DAV"
      },
      "source": [
        "## Install lime\n",
        "\n",
        "We use the lime library for explaining the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "IG4_gjzOzkEr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5111370-c980-41af-dde3-8e933cc4d7d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.9/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from lime) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.9/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from lime) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from lime) (4.65.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.9/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.12->lime) (2023.4.12)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.12->lime) (3.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.12->lime) (1.4.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.12->lime) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.12->lime) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.12->lime) (23.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->lime) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.18->lime) (3.1.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (1.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->lime) (3.15.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install lime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M71RuA7z5NP_"
      },
      "source": [
        "## Download NLTK dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8E1V_zARdPUZ",
        "outputId": "51f4b42b-c255-4266-a346-ec21628afe27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS2GcSm45Yys"
      },
      "source": [
        "## Connect to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykc-rYoT1aI6",
        "outputId": "bcb2b862-347c-4ac8-b2fa-802674d4d51a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQABbfGZ5oGd"
      },
      "source": [
        "## Unzip the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9DIidb55qqH",
        "outputId": "3f324d33-92f2-4f87-d9b1-9f5dbceedf88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/Sarcasm_Headlines_Dataset_v2.zip\n",
            "replace ./Sarcasm_Headlines_Dataset_v2.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "! unzip drive/MyDrive/Sarcasm_Headlines_Dataset_v2.zip -d ./"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IueMWas95sG2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgYxeSiOdPUa"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import pickle\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYAYpYV-57Rz"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwU4ZrGp6KKN"
      },
      "source": [
        "## Load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "OEc4asa8dPUa"
      },
      "outputs": [],
      "source": [
        "# Load the JSON file into a list\n",
        "with open('./Sarcasm_Headlines_Dataset_v2.json') as f:\n",
        "    data = f.readlines()\n",
        "\n",
        "# Parse each JSON string in the list\n",
        "parsed_data = [json.loads(d) for d in data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "LNn30u8HdPUb"
      },
      "outputs": [],
      "source": [
        "# Create a DataFrame from the parsed data with the 'headline' column included\n",
        "df = pd.DataFrame(parsed_data, columns=['is_sarcastic', 'headline', 'article_link'])\n",
        "df = df.drop('article_link', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED56zYVJ6PSA"
      },
      "source": [
        "## Validate the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "pB-531-ydPUb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d49d6107-623f-4546-c891-d1d2dc2450f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is_sarcastic    0\n",
            "headline        0\n",
            "dtype: int64\n",
            "116\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Check for duplicates\n",
        "print(df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eWwTUIV-pWZ"
      },
      "source": [
        "## Preprocess the data\n",
        "\n",
        "This part is commented out because the models give better results without the preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "YFdfm8VddPUb"
      },
      "outputs": [],
      "source": [
        "# Worse results with preprocessing\n",
        "# Preprocess the headlines - useless, vectorizer does this\n",
        "# df['headline'] = df['headline'].str.lower()\n",
        "# df['headline'] = df['headline'].apply(lambda x: x.split()) # use nltk tokenizer instead\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "# df['headline'] = df['headline'].apply(lambda x: [word for word in x if word not in stop_words])\n",
        "\n",
        "# # Stem the headlines\n",
        "# stemmer = PorterStemmer()\n",
        "# df['headline'] = df['headline'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "# df['headline'] = df['headline'].apply(lambda x: ' '.join(x))\n",
        "# print(df['headline'][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z2lCzG46UmK"
      },
      "source": [
        "## Train test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljMGDwjFdPUb",
        "outputId": "20d1ccfa-4716-44a2-fb33-c9bc2d1fce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thirtysomething scientists unveil doomsday clock of hair loss 1\n",
            "  (0, 18734)\t0.449539392876801\n",
            "  (0, 7568)\t0.5049956071401446\n",
            "  (0, 15425)\t0.28933989401228427\n",
            "  (0, 16750)\t0.400432629778379\n",
            "  (0, 7880)\t0.3925656546967618\n",
            "  (0, 17027)\t0.31798300078904773\n",
            "  (0, 21773)\t0.20882749752975768   (0, 22967)\t0.40267627245985715\n",
            "  (0, 20974)\t0.3308502517601071\n",
            "  (0, 20067)\t0.3369928164965712\n",
            "  (0, 19418)\t0.4150957696653228\n",
            "  (0, 19098)\t0.37424283376461503\n",
            "  (0, 16425)\t0.4270135553300358\n",
            "  (0, 6877)\t0.34658764993000457\n"
          ]
        }
      ],
      "source": [
        "# Extract the headlines and labels as separate arrays\n",
        "X = df['headline'].values\n",
        "y = df['is_sarcastic'].values\n",
        "print(X[0], y[0])\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert the headlines to a numerical representation using TF-IDF\n",
        "# tfidf = TfidfVectorizer(ngram_range=(1, 2))\n",
        "# tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "X_train = tfidf.fit_transform(X_train)\n",
        "X_test = tfidf.transform(X_test)\n",
        "print(X_train[0], X_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "9wlNVBIwYclb"
      },
      "outputs": [],
      "source": [
        "# Save tfidf\n",
        "tfidf_name = 'tfidf.sav'\n",
        "pickle.dump(tfidf, open(tfidf_name, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9UCVwZN6Z6f"
      },
      "source": [
        "# Models\n",
        "\n",
        "We decided to start with some basic algorithms, and then decide if it is worth to try more complicated ones. We tested and compared three different models - Naive Bayes algorithm, Logistic Regression, and Random Forest. The metrics used for the accuracies are: accuracy, precision, recall, and F1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYR5W1Rf62uG"
      },
      "source": [
        "## Naive Bayes algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "N9L8xN6OdPUc",
        "outputId": "c99acf8e-0818-4ea5-fe9b-6ba7b6aaf5f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "# Train the model using Naive Bayes algorithm\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8L-EofsAdPUc",
        "outputId": "06e3603e-76f4-4cce-e442-8a36268c7f82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 80.49%\n",
            "Precision: 82.14%\n",
            "Recall: 75.49%\n",
            "F1-score: 78.67%\n"
          ]
        }
      ],
      "source": [
        "# Predict on the testing set and evaluate the model's performance\n",
        "y_pred = naive_bayes.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "print(\"Precision: {:.2f}%\".format(precision*100))\n",
        "print(\"Recall: {:.2f}%\".format(recall*100))\n",
        "print(\"F1-score: {:.2f}%\".format(f1*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuMC9osW67rb"
      },
      "source": [
        "## Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "0pOLvboKdPUc",
        "outputId": "8de9cd0c-1b60-4866-9638-85ddc2db3c4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ],
      "source": [
        "# Train a logistic regression model\n",
        "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am3ygROZdPUc",
        "outputId": "1c831735-f2cf-4623-813b-7861709e2885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 79.87%\n",
            "Precision: 80.65%\n",
            "Recall: 76.04%\n",
            "F1-score: 78.27%\n"
          ]
        }
      ],
      "source": [
        "# Predict on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "print(\"Precision: {:.2f}%\".format(precision*100))\n",
        "print(\"Recall: {:.2f}%\".format(recall*100))\n",
        "print(\"F1-score: {:.2f}%\".format(f1*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "G9iFPAmaYcld"
      },
      "outputs": [],
      "source": [
        "# Save model\n",
        "clf_name = 'clf.sav'\n",
        "pickle.dump(clf, open(clf_name, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-jfJNUe6_aQ"
      },
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GhNhcXUAtdud"
      },
      "outputs": [],
      "source": [
        "# Train a random forest model\n",
        "rf = RandomForestClassifier(n_estimators=500)\n",
        "rf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hdObmLGEtjHT"
      },
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Calculate performance metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the performance metrics\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n",
        "print(\"Precision: {:.2f}%\".format(precision*100))\n",
        "print(\"Recall: {:.2f}%\".format(recall*100))\n",
        "print(\"F1-score: {:.2f}%\".format(f1*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXmVy7OP7Crn"
      },
      "source": [
        "## Conclusions\n",
        "\n",
        "Random forest is the slowest model, and there isn't significant difference in the accuracy compared to the two others. The Logistic Regression is best overall, because it is fast and with good results on all the metrics. Naive Bayes algorithm is better than the Logistic Regression only in the precision, but is worse in the three other metrics, so we decide to use the Logistic Regression.\n",
        "\n",
        "Since this model is fast with an accuracy around 84%, we decided to stick with it, because the more complicated models would take much more time to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nc3qVBDn9NSU"
      },
      "source": [
        "# Explain the model with Lime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7obwuDtL9U1T"
      },
      "source": [
        "## Set up a Lime model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mZ-mH14dPUc"
      },
      "outputs": [],
      "source": [
        "# Create a logistic regression model\n",
        "c = make_pipeline(tfidf, clf)\n",
        "\n",
        "# Explain the model's predictions using LIME\n",
        "explainer = LimeTextExplainer(class_names=[\"Not Sarcastic\", \"Sarcastic\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKIi7DUE-Aeh"
      },
      "source": [
        "## Example with a not-sarcastic headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7y15JszoYr4"
      },
      "outputs": [],
      "source": [
        "# Select a headline to explain\n",
        "headline_idx = 10\n",
        "headline = df['headline'][headline_idx]\n",
        "label = df['is_sarcastic'][headline_idx]\n",
        "\n",
        "print(headline)\n",
        "print(c.predict_proba([headline]))\n",
        "\n",
        "# Explain the headline\n",
        "exp = explainer.explain_instance(headline, c.predict_proba, num_features=len(headline.split()))\n",
        "print('Document id: %d' % headline_idx)\n",
        "print('Probability(sarcastic) =', c.predict_proba([headline])[0,1])\n",
        "print('True class: %s' % label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOnfhNuT-QHb"
      },
      "outputs": [],
      "source": [
        "# Visualise the explanation\n",
        "exp.show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ksbi3XuB-N-h"
      },
      "outputs": [],
      "source": [
        "# Print the explanation as list\n",
        "exp.as_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aTDY_ChO-HJx"
      },
      "source": [
        "## Example with a sarcastic headline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjCkT5oSr6gc"
      },
      "outputs": [],
      "source": [
        "# Select a headline to explain\n",
        "headline_idx = 4\n",
        "headline = df['headline'][headline_idx]\n",
        "label = df['is_sarcastic'][headline_idx]\n",
        "\n",
        "# Explain the headline\n",
        "exp = explainer.explain_instance(headline, c.predict_proba, num_features=len(headline.split()))\n",
        "print('Document id: %d' % headline_idx)\n",
        "print('Probability(sarcastic) =', c.predict_proba([headline])[0,1])\n",
        "print('True class: %s' % label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxG0Xmn6-c1e"
      },
      "outputs": [],
      "source": [
        "# Visualise the explanation\n",
        "exp.show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJyV1bYEstBB"
      },
      "outputs": [],
      "source": [
        "# Print the explanation as list\n",
        "exp.as_list()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCXPOYwyJRW-"
      },
      "source": [
        "## Validate\n",
        "\n",
        "We will try to remove some of the words in the headline that are marked sarcastic and non-sarcastic, and we expect to see that the prediction probabilities decrease and increase accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge7fCNR1MHdB"
      },
      "source": [
        "### Remove the most sarcastic word \"pretty\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFm4-zueJYT_"
      },
      "outputs": [],
      "source": [
        "headline_new = headline.replace(\"pretty\", \"\")\n",
        "\n",
        "# Explain the headline\n",
        "exp = explainer.explain_instance(headline_new, c.predict_proba, num_features=len(headline_new.split()))\n",
        "print('Document id: %d' % headline_idx)\n",
        "print('Probability(sarcastic) =', c.predict_proba([headline_new])[0,1])\n",
        "print('True class: %s' % label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9TpHP3tK-F_"
      },
      "outputs": [],
      "source": [
        "# Visualise the explanation\n",
        "exp.show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmxhDZFnMM06"
      },
      "source": [
        "### Remove the least sarcastic word \"mother\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbIpGOuALIkG"
      },
      "outputs": [],
      "source": [
        "headline_new = headline.replace(\"mother\", \"\")\n",
        "\n",
        "# Explain the headline\n",
        "exp = explainer.explain_instance(headline_new, c.predict_proba, num_features=len(headline_new.split()))\n",
        "print('Document id: %d' % headline_idx)\n",
        "print('Probability(sarcastic) =', c.predict_proba([headline_new])[0,1])\n",
        "print('True class: %s' % label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoLkD_EdLNNr"
      },
      "outputs": [],
      "source": [
        "# Visualise the explanation\n",
        "exp.show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfFYzzcZNxnU"
      },
      "source": [
        "### Remove the most not sarcastic word \"streaming\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3s0XVA5NeA5"
      },
      "outputs": [],
      "source": [
        "headline_new = headline.replace(\"streaming\", \"\")\n",
        "\n",
        "# Explain the headline\n",
        "exp = explainer.explain_instance(headline_new, c.predict_proba, num_features=len(headline_new.split()))\n",
        "print('Document id: %d' % headline_idx)\n",
        "print('Probability(sarcastic) =', c.predict_proba([headline_new])[0,1])\n",
        "print('True class: %s' % label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1-NHImoNgOX"
      },
      "outputs": [],
      "source": [
        "# Visualise the explanation\n",
        "exp.show_in_notebook(text=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z39P4_H-MSDC"
      },
      "source": [
        "### Conclusions\n",
        "\n",
        "As expected, the prediction probabilities changed. When we removed the most sarcastic word \"pretty\", the sarcasitc probability dropped from 88% to 78%. When we removed one of the least sarcastic word \"mother\", the sarcastic probability dropped only to 85%. Finally, when we removed the most non-sarcastic word \"streaming\", the sarcastic probability increased to 91%."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "cgCfVD4d405f"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}